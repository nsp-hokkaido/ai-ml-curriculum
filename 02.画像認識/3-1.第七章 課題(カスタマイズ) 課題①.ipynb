{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed03c83",
   "metadata": {},
   "source": [
    "# 【課題】顔認識処理を以下の観点でカスタマイズを実施する。\n",
    "#   課題① 難易度低\n",
    "顔認識結果をTrue／Falseではなく、True：\"SAM\",False\"Nobody\"として、名前表記に変更する  \n",
    "ヒント  \n",
    "[1]「結果格納エリア」 に「名前格納エリア」を追加する  \n",
    "[2]「検出した顔の数分、認識処理を実施する。」で、「認識結果を出力」で、結果Ture/Falseにより「名前を格納するエリア」に名前を格納する。  \n",
    "[3]「認識結果と値を書き込む」処理で、認識結果ではなく、名前を設定して表示する。(表示位置の微調整も行う)  \n",
    "[4]   出力するファイル名を「 output_name.jpg」に変更する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8c5fb8",
   "metadata": {},
   "source": [
    "---\n",
    "**「顔認識の基礎知識」で解説したOSSライブラリを使用して、**  \n",
    "**入力した写真から特定の人物の顔を認識させるプログラムです。** \n",
    "\n",
    "---\n",
    "### **■処理に必要なライブラリをインポートします【参考：第三章】**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d45c5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import face_recognition # Face recognition:顔認識\n",
    "import dlib             # Dlib:機械学習\n",
    "import cv2              # OpenCV:画像処理\n",
    "from matplotlib import pyplot as plt # 画像表示\n",
    "import time             # 処理時間計測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c94b8",
   "metadata": {},
   "source": [
    "### **■各種パラメータを設定します【参考：第六章、第七章】**\n",
    "\n",
    "①検出モデル  \n",
    "hog:計算量は少ないですが、精度は低いです。  \n",
    "cnn:計算量は多いですが、精度は高いです。  \n",
    "\n",
    "②顔検出精度  \n",
    "数字を大きくすると精度が上がりますが、計算量も上がります。デフォルトは1です。  \n",
    "2より大きくするとマシン負荷が高くなりすぎる可能性があります。  \n",
    "\n",
    "③顔認識の閾値  \n",
    "値を低くするほど判定が厳しくなり、高くするほど判定が緩くなります。デフォルトは0.6です。  \n",
    "複数の顔がある写真の認識で、ほとんどの顔が同一となった場合、  \n",
    "この数値を調整することで、より精度の高い認識を行うことができます。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03ee86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- パラメータ --------------------------------\n",
    "# 検出モデル\n",
    "MODEL = \"hog\"\n",
    "#MODEL = \"cnn\"\n",
    "\n",
    "# 顔検出精度\n",
    "UPSAMPLE = 1\n",
    "\n",
    "# 顔認識の閾値\n",
    "TOLERANCE = 0.6\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6eb3b9",
   "metadata": {},
   "source": [
    "### **■OpenCVを使って画像(顔写真)を入力します【参考：第四章】**\n",
    "\n",
    "顔認識対象の画像と顔認識させる画像の2枚を読み込みます。  \n",
    "\n",
    "OpenCV はカラーフォーマットが BGR 形式であるため、  \n",
    "一般的な RGB 形式にするためには、読み込み後に変換が必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80e8e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像ファイル読み込み\n",
    "image         = cv2.imread(r\"C:\\photo\\family_1_kid.jpg\") # 顔認識対象の顔画像\n",
    "unknown_image = cv2.imread(r\"C:\\photo\\family_1.jpg\")      # 顔認識させる画像\n",
    "\n",
    "# BGR→RGBに変換\n",
    "image         = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "unknown_image = cv2.cvtColor(unknown_image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5696126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_locations time :0.5149984359741211[sec]\n"
     ]
    }
   ],
   "source": [
    "# 時間計測 ： 開始時刻を記録\n",
    "cp_0 = time.time() \n",
    "\n",
    "# 画像に写っているすべての顔を検索\n",
    "face_locations = face_recognition.face_locations(unknown_image, model=MODEL, number_of_times_to_upsample=UPSAMPLE)\n",
    "\n",
    "# 時間計測 ： 終了時刻を記録\n",
    "cp_1 = time.time() \n",
    "time_hog = cp_1 - cp_0 # [終了時刻 - 開始時刻] から処理時間を算出 \n",
    "print (\"face_locations time :{0}\".format(time_hog) + \"[sec]\", flush=True)\n",
    "\n",
    "# 顔を検出できなかった場合、ここで終了\n",
    "if len(face_locations) <= 0:\n",
    "    raise SystemExit(\"Face Not Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df40ecca",
   "metadata": {},
   "source": [
    "### **■face_recognitionを使って写真から顔を検索します【参考：第五章、第六章】**\n",
    "\n",
    "画像に写っているすべての顔を検索します。  \n",
    "指定した検出モデルとアップサンプリング回数で処理を行います。\n",
    "\n",
    "検出モデルをcnnにしたり、アップサンプリング回数を増やすと、処理に時間が掛かります。  \n",
    "完了後に処理時間が表示されます。\n",
    "\n",
    "顔を検出できなかった場合はここで終了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def588e",
   "metadata": {},
   "source": [
    "### **■face_recognitionを使って顔認識を行います【参考：第七章】**\n",
    "\n",
    "検出した顔のデータを、認識させる顔データと比較して、認識結果と認識値を出力します。  \n",
    "検出した顔が複数ある場合、すべての顔データと比較します。\n",
    "\n",
    "認識結果は True/False のいずれかで出力します。  \n",
    "認識値は 0 に近いほど顔が似ていると判断したことになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ffe2f",
   "metadata": {},
   "source": [
    "### 課題① ヒント 1 (見たいときだけ下部を反転) \n",
    "「結果格納エリア」 に「名前格納エリア」を追加する  \n",
    "<span style=\"color: white \">\n",
    "namelist = []\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813aaa33",
   "metadata": {},
   "source": [
    "### 課題① ヒント 2 (見たいときだけ下部を反転)    \n",
    "「検出した顔の数分、認識処理を実施する。」で、「認識結果を出力」で、結果Ture/Falseにより「名前を格納するエリア」に名前を格納する。\n",
    "<span style=\"color: white \">\n",
    "    #顔の名前設定処理 初期値は\"Nobody\"  \n",
    "    name = \"Nobody\"  \n",
    "    #認識結果が「True」の場合、namelistに追加したface_nameを設定  \n",
    "    #認識結果が「False」の場合、namelistには初期値は\"Nobody\"を設定  \n",
    "    if True in results:  \n",
    "        name = \"SAM\"  \n",
    "    namelist.append(name)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08d1f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 3 face(s) in this photograph.\n",
      "[False]\n",
      "[0.76119687]\n",
      "[False]\n",
      "[0.60958992]\n",
      "[True]\n",
      "[0.0641367]\n"
     ]
    }
   ],
   "source": [
    "# 顔を検出できた場合、顔認識を行う\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "# 比較元の顔のエリアを指定する\n",
    "known_face_encodings = face_recognition.face_encodings(image)[0]\n",
    "\n",
    "# 検出した各顔の顔認識を行うループ\n",
    "resultslist = []\n",
    "distslist = []\n",
    "\n",
    "#課題① ヒント [1]「結果格納エリア」 に「名前格納エリア」を追加する\n",
    "# ここに処理を追加する\n",
    "#課題① ヒント[1] END    \n",
    "\n",
    "for index in range(len(face_locations)):\n",
    "\n",
    "    # 比較先の顔のエリアを指定する\n",
    "    unknown_encoding = face_recognition.face_encodings(unknown_image, face_locations)[index]\n",
    "\n",
    "    # 認識結果を出力\n",
    "    results = face_recognition.compare_faces([known_face_encodings], unknown_encoding, TOLERANCE)\n",
    "    print(results)\n",
    "    resultslist.append(results)\n",
    "    \n",
    "#課題① ヒント [2] 「検出した顔の数分、認識処理を実施する。」で、\n",
    "#           「認識結果を出力」で、結果Ture/Falseにより「名前を格納するエリア」に名前を格納する。\n",
    "# ここに処理を追加する\n",
    "#課題① ヒント[2] END    \n",
    "\n",
    "    # 認識値を出力\n",
    "    dists = face_recognition.face_distance([known_face_encodings], unknown_encoding)\n",
    "    print(dists)\n",
    "    distslist.append(dists)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb7bf2",
   "metadata": {},
   "source": [
    "### **■OpenCVを使って顔認識の結果を出力します【参考：第八章】**\n",
    "\n",
    "画像から検出した顔を枠で囲み、認識結果と認識値を描画します。\n",
    "\n",
    "描画後は別ウィンドウで画像を表示し、さらにファイルとして保存します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19cbb2",
   "metadata": {},
   "source": [
    "### 課題① ヒント 3 (見たいときだけ下部を反転) \n",
    "「認識結果と値を書き込む」処理で、認識結果ではなく、名前を設定して表示する。(表示位置の微調整も行う)   \n",
    "<span style=\"color: white \">\n",
    "    #cv2.putText(unknown_image, str(resultslist[index]), (right, bottom + 14), font, fontsize, font_color, 1)  \n",
    "    cv2.putText(unknown_image, str(namelist[index]), (right, bottom + 14), font, fontsize, font_color, 1)  \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d9cef",
   "metadata": {},
   "source": [
    "### 課題① ヒント 4 (見たいときだけ下部を反転) \n",
    "出力するファイル名を「 output_name.jpg」に変更する。  \n",
    "<span style=\"color: white \">\n",
    "    #cv2.imwrite(\"C:\\photo\\output.jpg\", output_image)  \n",
    "    cv2.imwrite(\"C:\\photo\\output_name.jpg\", output_image)  \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efcbc55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 認識した結果を画像に合成するループ\n",
    "rect_color = (0, 0, 255)     # 青枠\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "fontsize = 0.4\n",
    "font_color = (255, 255, 255) # 白文字\n",
    "index = 0\n",
    "for top, left, bottom, right in face_locations:\n",
    "    # 顔を枠で囲む\n",
    "    cv2.rectangle(unknown_image, (left, top), (right, bottom), rect_color, thickness=2)\n",
    "\n",
    "    # 認識結果と値を描き込む\n",
    "    cv2.rectangle(unknown_image, (right - 1, bottom), (right + 140, bottom + 20), rect_color, thickness=-1)\n",
    "#課題① ヒント [3] 「認識結果と値を書き込む」処理で、認識結果ではなく、名前を設定して表示する。(表示位置の微調整も行う) \n",
    "    cv2.putText(unknown_image, str(resultslist[index]), (right, bottom + 14), font, fontsize, font_color, 1)\n",
    "# 上記処理を変更する。\n",
    "#課題① ヒント[3] END    \n",
    "    cv2.putText(unknown_image, str(distslist[index]), (right + 50, bottom + 14), font, fontsize, font_color, 1)\n",
    "    index += 1\n",
    "\n",
    "# 画像を出力\n",
    "output_image = cv2.cvtColor(unknown_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#課題① ヒント [4] 出力するファイル名を「 output_name.jpg」に変更する。\n",
    "cv2.imwrite(\"C:\\photo\\output.jpg\", output_image)\n",
    "# 上記処理を変更する。\n",
    "#課題① ヒント[4] END\n",
    "cv2.imshow(\"image\",output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9ac19",
   "metadata": {},
   "source": [
    "■出力された画像について  \n",
    "・認識された顔：設定した名前【SAM】で表示  \n",
    "　※カスタマイズ前は「Ture」として表示  \n",
    "・認識されなかった顔：【Nobody】で表示  \n",
    "　※カスタマイズ前は「False」として表示  \n",
    "・数値：認識率  \n",
    "\n",
    "出力画像は「output_name.jpg」で保存される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff0c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37a329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7711d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
